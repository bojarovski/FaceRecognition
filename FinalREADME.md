---
title: "Sistem za preverjanje prisotnosti s prepoznavo obraza"
authors:
  - Marko Milenovic
  - Viktor Rackov
  - Mario Bojarovski
date: 2025-06-01
---

# Sistem za preverjanje prisotnosti s prepoznavo obraza

## Povzetek

Razvit je bil sistem za avtomatizirano preverjanje prisotnosti, ki temelji na prepoznavi obrazov v realnem Äasu. Sistem omogoÄa zaznavanje in identifikacijo oseb preko kamere ter samodejno beleÅ¾enje njihove prisotnosti v podatkovno bazo. Uporabnikom je na voljo spletni nadzorni vmesnik za upravljanje dogodkov in pregled zabeleÅ¾enih prisotnosti.

Poleg osnovne funkcionalnosti sistem vkljuÄuje tudi modul za prepoznavo Äustev, ki omogoÄa zaznavanje Äustvenega stanja udeleÅ¾encev in s tem dodaja kontekstualno vrednost zbranim podatkom. Za oceno uÄinkovitosti sistema je bila izvedena primerjalna analiza treh pristopov k prepoznavanju obrazov: privzetega modela iz knjiÅ¾nice `face_recognition`, modela ResNet-50 z uporabo prenosa znanja ter lastnega modela, razvitega z uporabo konvolucijske nevronske mreÅ¾e (CNN). Primerjava se je osredotoÄila na natanÄnost, hitrost uÄenja in sklepanja ter velikost posameznih modelov.

Rezultati analize so omogoÄili informirano izbiro najustreznejÅ¡ega modela za praktiÄno uporabo. Sistem deluje zanesljivo in uÄinkovito ter je primeren za Å¡irok nabor scenarijev sledenja prisotnosti.

## Uvod

V danaÅ¡njem digitalno preoblikovanem svetu postaja avtomatizacija vsakdanjih nalog vse pomembnejÅ¡a za uÄinkovito upravljanje virov, Äasa in ÄloveÅ¡kega dela. Eden od procesov, ki se Å¡e vedno pogosto izvaja roÄno, je spremljanje prisotnosti na dogodkih, predavanjih ali v delovnih okoljih. Tradicionalne metode â€“ kot so podpisovanje na papir, uporaba identifikacijskih kartic ali prijava prek terminalov â€“ so neuÄinkovite, nagnjene k napakam in zlahka zlorabljive. Poleg tega ne omogoÄajo sprotnega vpogleda v podatke ter pogosto zahtevajo dodatno obdelavo za analitiko in poroÄanje.

Za reÅ¡evanje teh izzivov smo razvili inteligentni sistem za preverjanje prisotnosti, ki temelji na raÄunalniÅ¡kem vidu in analizi obrazov v realnem Äasu. KljuÄna prednost sistema je popolna avtomatizacija: posamezniki so zaznani in identificirani s pomoÄjo kamere, njihova prisotnost pa se nemudoma in samodejno zabeleÅ¾i v podatkovno bazo. Tako se odpravi potreba po posredovanju osebja, poveÄa se natanÄnost ter omogoÄi hitrejÅ¡i odziv v primeru napak ali nepravilnosti.

Å e pred zaÄetkom razvoja celotnega sistema smo izvedli obseÅ¾no **analizo uÄinkovitosti treh razliÄnih modelov za prepoznavo obrazov**, da bi izbrali najprimernejÅ¡ega za uporabo v praksi:

- **Model A** temelji na knjiÅ¾nici `face_recognition`, ki uporablja dlib in CNN-enkoder za obraze.
- **Model B** je globoka nevronska mreÅ¾a **ResNet-50** s prenosom znanja.
- **Model C** pa je **lastno razvit konvolucijski model (CNN)**, zasnovan iz niÄ za veÄji nadzor in uÄinkovitost.

Vse modele smo preizkusili na istem naboru obrazov in jih ovrednotili glede na **natanÄnost, Äas uÄenja, hitrost sklepanja in porabo pomnilnika**. Na podlagi rezultatov smo izbrali najbolje delujoÄi model, ki smo ga nato integrirali v konÄni sistem za preverjanje prisotnosti.

Sistem je bil razvit tako, da je:

- **Zanesljiv** â€“ omogoÄa natanÄno identifikacijo tudi v dinamiÄnih okoljih.
- **Prilagodljiv** â€“ primeren za razliÄne scenarije, kot so Å¡ole, podjetja, konference in varnostni sistemi.
- **RazÅ¡irljiv** â€“ omogoÄa enostavno dodajanje dodatnih funkcionalnosti, kot so analiza Äustev in beleÅ¾enje metapodatkov.
- **Uporabniku prijazen** â€“ z intuitivno spletno nadzorno ploÅ¡Äo za upravljanje dogodkov, prisotnosti in izvoza podatkov.

KljuÄne komponente sistema vkljuÄujejo:

- **Spletno nadzorno ploÅ¡Äo** za ustvarjanje in upravljanje dogodkov, uporabnikov ter pregled zgodovine prisotnosti.
- **StreÅ¾niÅ¡ki API-sloj**, ki omogoÄa varno komunikacijo med komponentami in zanesljivo obdelavo podatkov.
- **Bazo podatkov**, kjer se shranjujejo uporabniÅ¡ki profili, dogodki, prisotnosti in spremljajoÄi metapodatki.
- **Modul za zaznavanje obrazov**, ki s pomoÄjo kamere deluje v realnem Äasu in primerja zaznane obraze z obstojeÄimi profili.

Pomembna nadgradnja sistema je tudi **modul za prepoznavo Äustev**, ki omogoÄa analizo obraznih izrazov in s tem dodaja dodatni kontekst zbranim podatkom. Ta funkcionalnost se lahko izkaÅ¾e za posebej uporabno pri spremljanju zadovoljstva, razpoloÅ¾enja zaposlenih ali v psiholoÅ¡ko usmerjenih analizah.

S tem projektom smo Å¾eleli pokazati, da je mogoÄe sodobne metode umetne inteligence povezati v enotno, uporabniku prijazno in uÄinkovito reÅ¡itev, ki ponuja realne prednosti v praksi in odpira pot nadaljnji nadgradnji, kot so sledenje vedenjskim vzorcem, napredna analitika in optimizacija delovnih procesov.

### Kako zagnati sistem

Projekt je bil razvit kot praktiÄen, funkcionalen sistem, ki omogoÄa sledenje prisotnosti z uporabo kamere, prepoznavo obrazov in upravljanje dogodkov preko spletnega vmesnika. Arhitektura je sestavljena iz veÄ povezanih komponent: React (frontend), Express.js (backend + MongoDB), Flask (most) in AI modul za zaznavo obrazov (dockeriziran Python modul). Za zagon celotnega sistema so na voljo pripravljene skripte, ki se nahajajo v mapi `scripts/`.

#### âœ… Prva namestitev (potrebno samo enkrat)

1. Nastavite virtualna okolja za backend (Express in Flask):

```bash
./scripts/setup_venvs.sh
```

2. Izgradite Docker sliko, ki vkljuÄuje podatkovno bazo in AI modul za prepoznavo obrazov:

```bash
./scripts/docker_build.sh
```

#### â–¶ï¸ Zagon sistema (ob vsakem zagonu)

Ko je okolje pripravljeno, je za delovanje sistema potrebno zagnati naslednje komponente:

1. Flask streÅ¾nik, ki deluje kot most med frontendom in AI modulom:

```bash
./scripts/run_flask.sh
```

2. Express.js streÅ¾nik, ki upravlja z MongoDB bazo uporabnikov in dogodkov:

```bash
./scripts/run_express.sh
```

3. Docker kontejner, ki vsebuje AI modul za zaznavo obrazov in prepoznavo oseb:

```bash
./scripts/docker_run.sh
```

#### ğŸŒ Zagon spletnega vmesnika

V mapi `Dashboard/` zaÅ¾enite React aplikacijo:

```bash
npm run start
```

#### ğŸ“Œ Uporaba

Po uspeÅ¡nem zagonu vseh komponent je sistem dostopen preko spletnega brskalnika. Uporabnik lahko:

- ustvarja in upravlja dogodke,
- dodaja nove uporabnike z njihovimi slikami,
- spremlja prisotnost v realnem Äasu,
- pregleduje zgodovino prisotnosti in izvozi podatke po potrebi.

Model za prepoznavo obrazov je nameÅ¡Äen in zagnan znotraj Docker okolja. VkljuÄuje vse slike oseb, ki se nahajajo v mapi `AI/training_images/`, in jih obdeluje s pomoÄjo knjiÅ¾nice `face_recognition`. Sistem temelji na prej izvedeni analizi uÄinkovitosti razliÄnih modelov (glej poglavje _Poskusi in rezultati_) in je zasnovan tako, da se ob zagonu samodejno naloÅ¾i najbolj optimalni model.

ÄŒe Å¾elite dodati novo osebo za prepoznavo, preprosto dodajte njeno sliko v mapo `AI/training_images/` (z ustreznim imenom, npr. `Janez.jpg`) in zaÅ¾enite naslednjo skripto:

```bash
python training_script.py
```

S tem se bo samodejno posodobila datoteka `known_faces.pkl`, ki jo AI modul uporablja za prepoznavo obrazov.

## Metodologija

Razvoj sistema je potekal v dveh fazah. V prvi fazi smo izvedli testiranje razliÄnih pristopov za prepoznavo obrazov, v drugi pa integracijo najbolje delujoÄega modela v sistem za preverjanje prisotnosti.

#### ğŸ“Œ Faza 1: Primerjava modelov za prepoznavo obrazov

Uporabili smo javno dostopen podatkovni nabor s portala Kaggle:  
ğŸ”— **[Face Recognition Dataset â€“ vasukipatel](https://www.kaggle.com/datasets/vasukipatel/face-recognition-dataset)**

ğŸ“Š **Povzetek nabora podatkov**:

- Skupno Å¡tevilo slik: **2.562**
- Skupno Å¡tevilo oseb: **31**
- PovpreÄno Å¡tevilo slik na osebo: **82.65**
- Najmanj slik na osebo: **30**
- NajveÄ slik na osebo: **120**

Na spodnji sliki je prikazano Å¡tevilo slik na posamezno osebo znotraj nabora:

![Porazdelitev slik po osebah](dataset_distribution.png)

Podatkovni nabor smo razdelili v razmerju 70:15:15 (uÄenje:validacija:test). Na podlagi tega smo primerjali naslednje tri modele:

Podatkovni nabor smo razdelili v razmerju 70:15:15 (uÄenje:validacija:test). Na podlagi tega smo primerjali naslednje tri modele:

#### Model A â€“ `face_recognition` (dlib-based CNN)

- Uporablja knjiÅ¾nico `face_recognition`, ki temelji na `dlib` in CNN za generacijo 128-dimenzionalnih vektorskih predstavitev obrazov.
- Obrazi so kodirani s funkcijo `face_encodings()` in primerjani z Å¾e znanimi predstavitvami z `compare_faces()` in `face_distance()`.
- Model ne zahteva dodatnega treniranja, saj deluje po principu primerjave z Å¾e shranjenimi kodami znanih obrazov.

#### Model B â€“ ResNet-50 z uporabo prenosa uÄenja

- Uporabljena je bila predtrenirana arhitektura `ResNet-50` iz `torchvision.models`.
- Zadnji **klasifikacijski sloj `fc` (Fully Connected)** je bil zamenjan z novim `Linear` slojem z izhodom v velikosti Å¡tevila razredov (31).
- Treniranje je bilo izvedeno s `Adam` optimizerjem, `CrossEntropyLoss` funkcijo izgube in `StepLR` schedulerjem.
- Vhodne slike so bile obdelane z `RandomResizedCrop`, `HorizontalFlip`, `ColorJitter` in `Normalize`.

#### Model C â€“ Lastna CNN arhitektura

- Model je bil roÄno definiran s pomoÄjo `torch.nn.Module`.
- Arhitektura sledi tipiÄni strukturi CNN z zaporednimi bloki:
  - **Blok 1:** `Conv2d â†’ BatchNorm2d â†’ ReLU â†’ MaxPool2d`
  - **Blok 2:** `Conv2d â†’ BatchNorm2d â†’ ReLU â†’ MaxPool2d`
  - **Blok 3:** `Conv2d â†’ BatchNorm2d â†’ ReLU â†’ MaxPool2d`
  - Nato sledi **Flatten** in zakljuÄni klasifikacijski del:
  - `Dropout â†’ Linear â†’ ReLU â†’ Dropout â†’ Linear (izhod = 31)`
- Uporabljen je bil `SGD` optimizer, `CrossEntropyLoss` in `MultiStepLR` scheduler.
- Slike so bile predhodno obdelane z `Resize`, `RandomHorizontalFlip`, `RandomRotation`, `ColorJitter` in `Normalize`.

#### ğŸ“Š Metodologija vrednotenja

Za primerjavo modelov smo uporabili naslednje metrike:

- **Accuracy (%):** razmerje pravilno klasificiranih primerov
- **Precision (%):** TP / (TP + FP)
- **Recall (%):** TP / (TP + FN)
- **F1-Score (%):** 2 _ (precision _ recall) / (precision + recall)
- **Training Time (s):** Äas potreb za treniranje modela
- **Inference Speed (faces/s):** Å¡tevilo prepoznanih obrazov na sekundo
- **Model Size (MB):** velikost modela na disku

Vrednosti metrik so bile izraÄunane na testnem delu podatkovnega nabora. Rezultati so bili prikazani v tabelah in grafih (stolpÄni diagrami, radar graf).

### ğŸ“¦ Faza 2: Integracija sistema

Na podlagi rezultatov testiranja iz faze 1 smo v sistem integrirali model A â€” knjiÅ¾nico `face_recognition`, saj je pokazala najboljÅ¡e razmerje med hitrostjo in natanÄnostjo (glej poglavje _Poskusi in rezultati_). Sistem smo zasnovali kot razÅ¡irljiv in modularen, pri Äemer je vsak del aplikacije odgovoren za toÄno doloÄeno nalogo.

#### ğŸ§© Pregled arhitekture sistema

Celoten sistem je sestavljen iz naslednjih komponent:

**1. ğŸ“· Kamera + AI modul (Docker)**  
Modul za prepoznavo obrazov je implementiran v jeziku Python z uporabo knjiÅ¾nice `face_recognition`. Kamera prek modula `camera_client.py` zajema slike in jih poÅ¡ilja v zaledni API `/recognize`, ki vrne seznam prepoznanih oseb.  
Modul deluje znotraj Docker okolja in uporablja `known_faces.pkl` za vnaprej nauÄene vektorske predstavitve uporabnikov.

**2. ğŸ§  Prepoznavanje Äustev**  
Vzpostavljen je loÄen Flask streÅ¾nik (na portu 5002), ki uporablja knjiÅ¾nico `deepface` za zaznavo obraznih Äustev. Vhodna slika je kodirana v base64 in poslana na `/analyse`, kjer se izvede analiza Äustev z uporabo modela RetinaFace.

**3. ğŸ¥ AI kontrolni most (Flask bridge)**  
Komponenta `AI_Control/app.py` deluje kot vmesnik med uporabniÅ¡kim vmesnikom (frontend) in AI modulom. OmogoÄa zagon in zaustavitev modula za prepoznavo prek HTTP zahtevkov na `/start-camera` in `/stop-camera`.

**4. ğŸŒ Express.js streÅ¾nik**  
Glavni streÅ¾nik zaledja je implementiran v Express.js in zagotavlja REST API za delo z dogodki, uporabniki in prisotnostjo.  
Moduli vkljuÄujejo:

- `routes/attendanceRoutes.js`: beleÅ¾i prisotnost glede na ID uporabnika ali prepoznano ime.
- `routes/eventRoutes.js`: ustvarjanje, brisanje in upravljanje dogodkov.
- `routes/userRoutes.js`: dodajanje novih uporabnikov z moÅ¾nostjo nalaganja slike (Multer).
- Podatki se hranijo v MongoDB prek modelov `User`, `Event` in `Attendance`.

**5. ğŸ’» React frontend (Dashboard)**  
UporabniÅ¡ki vmesnik omogoÄa organizatorjem dogodkov:

- ustvarjanje novih dogodkov,
- zagon kamere z dodeljenim dogodkom,
- pregled udeleÅ¾encev in njihove prisotnosti v realnem Äasu,
- izvoz in brisanje dogodkov po potrebi.

Glavne funkcionalnosti vkljuÄujejo:

- Komunikacijo s streÅ¾niki na `localhost:5000`, `localhost:4000` in `localhost:5001`.
- Vmesnik za zagon AI kamere in zaustavitev.
- Vizualizacijo prisotnosti s pomoÄjo material-ui komponent.

#### ğŸ–¼ï¸ Diagram arhitekture sistema

Spodnji diagram prikazuje medsebojne povezave med komponentami sistema:

![Diagram arhitekture](system_diagram.png)

## ğŸ“Š Rezultati

Po izvedbi faze testiranja smo primerjali tri modele glede na razliÄne metrike, pri Äemer smo uporabili skupno 2562 slik iz javno dostopnega nabora podatkov z 31 razliÄnimi osebami. Ocena je bila izvedena na testnem delu podatkovnega nabora.

Uporabljene metrike:

- **Accuracy (%):** DeleÅ¾ pravilno prepoznanih primerov.
- **Precision (%):** NatanÄnost klasifikacije (TP / (TP + FP)).
- **Recall (%):** ObÄutljivost modela (TP / (TP + FN)).
- **F1-Score (%):** Harmonizirana sredina med precision in recall.
- **Training Time (s):** ÄŒas treniranja modela v sekundah.
- **Inference Speed (faces/s):** Å tevilo obrazov, ki jih model obdeluje na sekundo.

### ğŸ“ Kvantitativna primerjava modelov

| Model   | Accuracy (%) | Precision (%) | Recall (%) | F1-Score (%) | Training Time (s) | Inference Speed (faces/s) |
| ------- | ------------ | ------------- | ---------- | ------------ | ----------------- | ------------------------- |
| Model A | 97.24        | 97.94         | 96.20      | 96.49        | 1939.91           | 1.17                      |
| Model B | 85.60        | 87.29         | 85.53      | 85.33        | 834.45            | 38.16                     |
| Model C | 27.63        | 25.87         | 25.90      | 24.14        | 1021.56           | 39.97                     |

### ğŸ“ˆ Vizualna primerjava

#### ğŸ“Š StolpÄni in radar grafi

Na spodnji sliki so prikazani:

- StolpÄni diagrami za _accuracy_, _F1-score_, _Äas treniranja_ in _hitrost sklepanja_
- Radar graf, ki prikazuje primerjavo Å¡tirih kljuÄnih metrik

![Vizualni prikaz rezultatov](model_comparison.png)

#### ğŸ•¸ï¸ Radar graf â€“ celostna zmogljivost modelov

![Radar graf](radar_chart.png)

### ğŸ” Matrike zmede

Za vsakega izmed modelov smo generirali matriko zmede, ki prikazuje Å¡tevilo pravilnih in nepravilnih klasifikacij po posameznih osebah.

- **Model A** â€“ `face_recognition`:

  ![Confusion Matrix â€“ Model A](conf_a.png)

- **Model B** â€“ `ResNet-50`:

  ![Confusion Matrix â€“ Model B](conf_b.png)

- **Model C** â€“ Custom CNN:

  ![Confusion Matrix â€“ Model C](conf_c.png)

---

Na podlagi prikazanih rezultatov je bil za produkcijsko integracijo izbran **Model A**, saj je dosegel najviÅ¡jo natanÄnost in F1-mero, kar je kljuÄno za zanesljivo prepoznavo obrazov v realnem Äasu.
